{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Saliency_system.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nilesh0109/CV2_SoSe_19/blob/master/Saliency_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxwVzzyrpD2R",
        "colab_type": "code",
        "outputId": "aab9b95c-874d-484d-b114-f3577d29fde0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "import zipfile\n",
        "from google.colab import files, drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK13Xnq_pG2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/Colab Notebooks/CV2 exercies/Archive.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EayiS3g6pJ8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import imageio\n",
        "from __future__ import division\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBWzAZLlpLcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ROOT= '/tmp'\n",
        "NUM_IMAGES = 1200\n",
        "VAL_NUM_IMAGES = 400\n",
        "\n",
        "def load_train_data():\n",
        "  training_img_directory = ROOT+'/data/train/images'\n",
        "  training_fixation_directory = ROOT+'/data/train/fixations'\n",
        "  val_img_directory = ROOT+'/data/val/images'\n",
        "  val_fixation_directory = ROOT+'/data/val/fixations'\n",
        "  train_imgs = np.zeros((NUM_IMAGES + VAL_NUM_IMAGES, 180, 320, 3), dtype=np.uint8)\n",
        "  train_fixations = np.zeros((NUM_IMAGES + VAL_NUM_IMAGES, 180, 320, 1), dtype=np.uint8)\n",
        "  \n",
        "  for i in range(1, NUM_IMAGES + 1):\n",
        "    img_file = os.path.join(training_img_directory, '{:04d}.jpg'.format(i))\n",
        "    fixation_file = os.path.join(training_fixation_directory, '{:04d}.jpg'.format(i))\n",
        "    train_imgs[i-1] = imageio.imread(img_file)\n",
        "    fixation = imageio.imread(fixation_file)\n",
        "    train_fixations[i-1] = np.expand_dims(fixation, -1) # adds singleton dimension so fixation size is (180,320,1)\n",
        "  \n",
        "  for j in range(i + 1, i + VAL_NUM_IMAGES + 1):\n",
        "    img_file = os.path.join(val_img_directory, '{:04d}.jpg'.format(j))\n",
        "    fixation_file = os.path.join(val_fixation_directory, '{:04d}.jpg'.format(j))\n",
        "    train_imgs[j-1] = imageio.imread(img_file)\n",
        "    fixation = imageio.imread(fixation_file)\n",
        "    train_fixations[j-1] = np.expand_dims(fixation, -1) # adds singleton dimension so fixation size is (180,320,1)\n",
        "    \n",
        "  return train_imgs, train_fixations\n",
        "\n",
        "# Generator function will output one (image, target) tuple at a time,\n",
        "# and shuffle the data for each new epoch\n",
        "def data_generator(imgs, targets):\n",
        "\twhile True: # produce new epochs forever\n",
        "\t\t# Shuffle the data for this epoch\n",
        "\t\tidx = np.arange(imgs.shape[0])\n",
        "\t\tnp.random.shuffle(idx)\n",
        "\n",
        "\t\timgs = imgs[idx]\n",
        "\t\ttargets = targets[idx]\n",
        "\t\tfor i in range(imgs.shape[0]):\n",
        "\t\t\tyield imgs[i], targets[i]\n",
        "\n",
        "def get_batch_from_generator(gen, batchsize):\n",
        "\tbatch_imgs = []\n",
        "\tbatch_fixations = []\n",
        "\tfor i in range(batchsize):\n",
        "\t\timg, target = gen.__next__()\n",
        "\t\tbatch_imgs.append(img)\n",
        "\t\tbatch_fixations.append(target)\n",
        "\treturn np.array(batch_imgs), np.array(batch_fixations)  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFi73W_n0rEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tf.reset_default_graph()\n",
        "\n",
        "'''\n",
        "Model class\n",
        "'''\n",
        "\n",
        "class saliencyModel:\n",
        "  def __init__(self, model_weights=None, learning_rate=1e-4, batch_size=32, num_epochs=100, prior_downsampling_factor=10):\n",
        "    self.dir_path = 'drive/My Drive/Colab Notebooks/CV2 exercies/'\n",
        "    self.model_path = self.dir_path+'model_cptk/my-model1'\n",
        "    self.lr_rate = learning_rate\n",
        "    self.batch_size = batch_size\n",
        "    self.num_epochs = num_epochs\n",
        "    self.prior_downsampling_factor = prior_downsampling_factor\n",
        "    self.input_h = 180\n",
        "    self.input_w = 320\n",
        "    self.prior_h = self.input_h /(2 * prior_downsampling_factor)\n",
        "    self.prior_w = self.input_w / (2 * prior_downsampling_factor)\n",
        "    self.reg_lambda = 1 / (self.prior_h * self.prior_w)\n",
        "    self.input_images_placeholder = tf.placeholder(tf.uint8, [None, self.input_h, self.input_w, 3])\n",
        "    self.target_images_placeholder = tf.placeholder(tf.uint8, [None, self.input_h, self.input_w, 1])\n",
        "    \n",
        "    if model_weights is not None:\n",
        "      self.load_weights(model_weights)\n",
        "    \n",
        "  def load_weights(self, model_weights):\n",
        "    vgg_weight_file = model_weights\n",
        "    self.weights = np.load(vgg_weight_file)\n",
        "  \n",
        "  def setup(self, mode= 'Train'):\n",
        "    \n",
        "    with tf.name_scope('preprocessing') as scope:\n",
        "      input_imgs = tf.image.convert_image_dtype(self.input_images_placeholder, tf.float32) * 255\n",
        "      fixations_normalized = tf.image.convert_image_dtype(self.target_images_placeholder, tf.float32)\n",
        "      mean = tf.constant([123.68 , 116.779 , 103.939], dtype = tf.float32, shape =[1,1,1,3], name ='img_mean')\n",
        "      imgs_normalized = input_imgs - mean\n",
        "\n",
        "    with tf.name_scope('conv1_1') as scope:\n",
        "      kernel = tf.Variable(initial_value=self.weights['conv1_1_W'], trainable=False, name=\"weights\")\n",
        "      biases = tf.Variable(initial_value=self.weights['conv1_1_b'], trainable=False, name=\"biases\")\n",
        "      conv = tf.nn.conv2d(imgs_normalized, kernel, [1, 1, 1, 1], padding='SAME')\n",
        "      out = tf.nn.bias_add(conv, biases)\n",
        "      act = tf.nn.relu(out, name=scope)\n",
        "\n",
        "    with tf.name_scope('conv1_2') as scope:\n",
        "      kernel = tf.Variable(initial_value=self.weights['conv1_2_W'], trainable=False, name=\"weights\")\n",
        "      biases = tf.Variable(initial_value=self.weights['conv1_2_b'], trainable=False, name=\"biases\")\n",
        "      conv = tf.nn.conv2d(act, kernel, [1, 1, 1, 1], padding='SAME')\n",
        "      out = tf.nn.bias_add(conv, biases)\n",
        "      act = tf.nn.relu(out, name=scope)\n",
        "\n",
        "    with tf.name_scope('pool1') as scope:\n",
        "      pool = tf.layers.max_pooling2d(act, pool_size=(2,2), strides=(2,2), padding='same')\n",
        "\n",
        "    with tf.name_scope('conv2_1') as scope:\n",
        "      kernel = tf.Variable(initial_value=self.weights['conv2_1_W'], trainable=False, name=\"weights\")\n",
        "      biases = tf.Variable(initial_value=self.weights['conv2_1_b'], trainable=False, name=\"biases\")\n",
        "      conv = tf.nn.conv2d(pool, kernel, [1, 1, 1, 1], padding='SAME')\n",
        "      out = tf.nn.bias_add(conv, biases)\n",
        "      act = tf.nn.relu(out, name=scope)\n",
        "\n",
        "    with tf.name_scope('conv2_2') as scope:\n",
        "      kernel = tf.Variable(initial_value=self.weights['conv2_2_W'], trainable=False, name=\"weights\")\n",
        "      biases = tf.Variable(initial_value=self.weights['conv2_2_b'], trainable=False, name=\"biases\")\n",
        "      conv = tf.nn.conv2d(act, kernel, [1, 1, 1, 1], padding='SAME')\n",
        "      out = tf.nn.bias_add(conv, biases)\n",
        "      act = tf.nn.relu(out, name=scope)\n",
        "\n",
        "    with tf.name_scope('pool2') as scope:\n",
        "      pool2 = tf.layers.max_pooling2d(act, pool_size=(2,2), strides=(2,2), padding='same')\n",
        "\n",
        "    with tf.name_scope('conv3_1') as scope:\n",
        "      kernel = tf.Variable(initial_value=self.weights['conv3_1_W'], trainable=False, name=\"weights\")\n",
        "      biases = tf.Variable(initial_value=self.weights['conv3_1_b'], trainable=False, name=\"biases\")\n",
        "      conv = tf.nn.conv2d(pool2, kernel, [1, 1, 1, 1], padding='SAME')\n",
        "      out = tf.nn.bias_add(conv, biases)\n",
        "      act = tf.nn.relu(out, name=scope)\n",
        "\n",
        "    with tf.name_scope('conv3_2') as scope:\n",
        "      kernel = tf.Variable(initial_value=self.weights['conv3_2_W'], trainable=False, name=\"weights\")\n",
        "      biases = tf.Variable(initial_value=self.weights['conv3_2_b'], trainable=False, name=\"biases\")\n",
        "      conv = tf.nn.conv2d(act, kernel, [1, 1, 1, 1], padding='SAME')\n",
        "      out = tf.nn.bias_add(conv, biases)\n",
        "      act = tf.nn.relu(out, name=scope)\n",
        "\n",
        "    with tf.name_scope('conv3_3') as scope:\n",
        "      kernel = tf.Variable(initial_value=self.weights['conv3_3_W'], trainable=False, name=\"weights\")\n",
        "      biases = tf.Variable(initial_value=self.weights['conv3_3_b'], trainable=False, name=\"biases\")\n",
        "      conv = tf.nn.conv2d(act, kernel, [1, 1, 1, 1], padding='SAME')\n",
        "      out = tf.nn.bias_add(conv, biases)\n",
        "      act = tf.nn.relu(out, name=scope)\n",
        "\n",
        "    with tf.name_scope('pool3') as scope:\n",
        "      pool3 = tf.layers.max_pooling2d(act, pool_size=(2,2), strides=(1,1), padding='same')\n",
        "\n",
        "    with tf.name_scope('conv4_1') as scope:\n",
        "      kernel = tf.Variable(initial_value=self.weights['conv4_1_W'], trainable=False, name=\"weights\")\n",
        "      biases = tf.Variable(initial_value=self.weights['conv4_1_b'], trainable=False, name=\"biases\")\n",
        "      conv = tf.nn.conv2d(pool3, kernel, [1, 1, 1, 1], padding='SAME')\n",
        "      out = tf.nn.bias_add(conv, biases)\n",
        "      act = tf.nn.relu(out, name=scope)\n",
        "      \n",
        "    with tf.name_scope('conv4_2') as scope:\n",
        "      kernel = tf.Variable(initial_value=self.weights['conv4_2_W'], trainable=False, name=\"weights\")\n",
        "      biases = tf.Variable(initial_value=self.weights['conv4_2_b'], trainable=False, name=\"biases\")\n",
        "      conv = tf.nn.conv2d(act, kernel, [1, 1, 1, 1], padding='SAME')\n",
        "      out = tf.nn.bias_add(conv, biases)\n",
        "      act = tf.nn.relu(out, name=scope)\n",
        "    \n",
        "    with tf.name_scope('conv4_3') as scope:\n",
        "      kernel = tf.Variable(initial_value=self.weights['conv4_3_W'], trainable=False, name=\"weights\")\n",
        "      biases = tf.Variable(initial_value=self.weights['conv4_3_b'], trainable=False, name=\"biases\")\n",
        "      conv = tf.nn.conv2d(act, kernel, [1, 1, 1, 1], padding='SAME')\n",
        "      out = tf.nn.bias_add(conv, biases)\n",
        "      act = tf.nn.relu(out, name=scope)\n",
        "      \n",
        "    with tf.name_scope('pool4') as scope:\n",
        "      pool4 = tf.layers.max_pooling2d(act, pool_size=(2,2), strides=(1,1), padding='same')\n",
        "    \n",
        "    with tf.name_scope('conv5_1') as scope:\n",
        "      kernel = tf.Variable(initial_value=self.weights['conv5_1_W'], trainable=False, name=\"weights\")\n",
        "      biases = tf.Variable(initial_value=self.weights['conv5_1_b'], trainable=False, name=\"biases\")\n",
        "      conv = tf.nn.conv2d(pool4, kernel, [1, 1, 1, 1], padding='SAME')\n",
        "      out = tf.nn.bias_add(conv, biases)\n",
        "      act = tf.nn.relu(out, name=scope)\n",
        "      \n",
        "    with tf.name_scope('conv5_2') as scope:\n",
        "      kernel = tf.Variable(initial_value=self.weights['conv5_2_W'], trainable=False, name=\"weights\")\n",
        "      biases = tf.Variable(initial_value=self.weights['conv5_2_b'], trainable=False, name=\"biases\")\n",
        "      conv = tf.nn.conv2d(act, kernel, [1, 1, 1, 1], padding='SAME')\n",
        "      out = tf.nn.bias_add(conv, biases)\n",
        "      act = tf.nn.relu(out, name=scope)\n",
        "    \n",
        "    with tf.name_scope('conv5_3') as scope:\n",
        "      kernel = tf.Variable(initial_value=self.weights['conv5_3_W'], trainable=False, name=\"weights\")\n",
        "      biases = tf.Variable(initial_value=self.weights['conv5_3_b'], trainable=False, name=\"biases\")\n",
        "      conv = tf.nn.conv2d(act, kernel, [1, 1, 1, 1], padding='SAME')\n",
        "      out = tf.nn.bias_add(conv, biases)\n",
        "      act = tf.nn.relu(out, name=scope)\n",
        "      conv5_3 = act\n",
        "      \n",
        "    with tf.name_scope('concat_featuremaps') as scope:\n",
        "      concatenated_feature_maps = tf.concat([pool2, pool3, pool4, conv5_3], axis=3)\n",
        "      print('IN_TRAINING_MODE is',mode =='Train')\n",
        "      regularized_feature_maps = tf.layers.dropout(concatenated_feature_maps, rate=0.5, training= mode =='Train')\n",
        "\n",
        "    with tf.name_scope('featuremaps_conv1') as scope:\n",
        "      my_regularizer = tf.contrib.layers.l2_regularizer(1e-5)\n",
        "      act_featuremaps_conv1 = tf.layers.conv2d(regularized_feature_maps, filters=64, kernel_size=(3,3), padding='SAME', activation=tf.nn.relu, name='featuremaps_conv1', kernel_regularizer = my_regularizer, reuse=tf.AUTO_REUSE)\n",
        "\n",
        "    with tf.name_scope('featuremaps_conv2') as scope:\n",
        "      act_featuremaps_conv2 = tf.layers.conv2d(act_featuremaps_conv1, filters=1, kernel_size=(1,1), activation=tf.nn.relu, name='featuremaps_conv2', kernel_regularizer = my_regularizer, reuse=tf.AUTO_REUSE)\n",
        "\n",
        "    with tf.name_scope('Learned_prior') as scope:\n",
        "      prior_shape = (1, self.prior_h, self.prior_w,1)\n",
        "      prior = tf.Variable(tf.ones(prior_shape), name=\"prior\", trainable=True)\n",
        "      upsampled_prior = tf.image.resize_bilinear(prior, size=act_featuremaps_conv2.shape[1:3])\n",
        "      saliency_mixed = tf.multiply(act_featuremaps_conv2, upsampled_prior)\n",
        "      saliency_raw = tf.nn.relu(saliency_mixed)\n",
        "      \n",
        "    with tf.name_scope('loss') as scope:\n",
        "      upsampled_saliency = tf.image.resize_bilinear(saliency_raw, size=fixations_normalized.shape[1:3])\n",
        "      # normalize saliency\n",
        "      max_value_per_image = tf.reduce_max(upsampled_saliency, axis=[1,2,3], keepdims=True)\n",
        "      predicted_saliency = (upsampled_saliency / max_value_per_image)\n",
        "      \n",
        "      # Loss function from Cornia et al. (2016) [with higher weight for salient pixels]\n",
        "      alpha = 1.01\n",
        "      weight = 1.0 / (alpha - fixations_normalized)\n",
        "      loss = tf.losses.mean_squared_error(labels=fixations_normalized, \n",
        "                        predictions=predicted_saliency, \n",
        "                        weights=weight)\n",
        "      regularizer = tf.nn.l2_loss(1 - prior)\n",
        "      loss += tf.reduce_mean(self.reg_lambda * regularizer)\n",
        "      l2_loss = tf.losses.get_regularization_loss() \n",
        "      loss += l2_loss\n",
        "      \n",
        "    return predicted_saliency, loss\n",
        "    \n",
        "  def train(self, t_imgs, t_fixations):\n",
        "    \n",
        "    pred_val ,loss_op_val = self.setup(mode='Test')\n",
        "    pred ,loss_op = self.setup(mode='Train')\n",
        "    training_loss = []\n",
        "    val_loss = []\n",
        "    \n",
        "    # Optimizer settings from Cornia et al. (2016) [except for decay]\n",
        "    optimizer = tf.train.MomentumOptimizer(learning_rate=self.lr_rate, momentum=0.9, use_nesterov=True)\n",
        "    minimize_op = optimizer.minimize(loss_op)\n",
        "    saver = tf.train.Saver()\n",
        "    \n",
        "    with tf.Session() as sess:\n",
        "      #writer = tf.summary.FileWriter(logdir=\"./\", graph=sess.graph)\n",
        "      sess.run(tf.global_variables_initializer())\n",
        "      saver.restore(sess, \"model/latest1\")\n",
        "      for epoch_ind in range(0, self.num_epochs, 5):\n",
        "        kf = KFold(n_splits=5)\n",
        "        for train_index, val_index in kf.split(t_imgs):\n",
        "          train_gen = data_generator(t_imgs[train_index], t_fixations[train_index])\n",
        "          val_gen = data_generator(t_imgs[val_index], t_fixations[val_index])\n",
        "          \n",
        "          num_batches = len(train_index) // self.batch_size\n",
        "          for b in range(num_batches):\n",
        "            batch_imgs, batch_fixations = get_batch_from_generator(train_gen, self.batch_size)\n",
        "            predication, batch_loss,_ = sess.run([pred, loss_op, minimize_op], feed_dict={self.input_images_placeholder: batch_imgs, self.target_images_placeholder: batch_fixations})\n",
        "          training_loss.append(batch_loss)\n",
        "          \n",
        "        if epoch_ind % 5 == 0:\n",
        "          #writer.add_summary(l_summary, global_step=b)\n",
        "          print('epoch {0} done: TRAINING batch loss {1}'.format(epoch_ind, batch_loss))\n",
        "            \n",
        "        if epoch_ind % 100 == 0:\n",
        "          val_batch_imgs, val_batch_fixations = get_batch_from_generator(val_gen, self.batch_size)\n",
        "          prediction_val, batch_loss_val = sess.run([pred_val, loss_op_val], feed_dict={self.input_images_placeholder: val_batch_imgs, self.target_images_placeholder: val_batch_fixations})\n",
        "          print('epoch {0} VALIDATION batch loss {1}'.format(epoch_ind, batch_loss_val))\n",
        "          val_loss.append(batch_loss_val)\n",
        "          \n",
        "        if epoch_ind % 500 == 0 and epoch_ind != 0:\n",
        "          save_path = saver.save(sess, 'model/latest1', global_step=epoch_ind)\n",
        "      save_path = saver.save(sess, 'model/latest1')\n",
        "      \n",
        "      \n",
        "  def test(self, test_imgs):\n",
        "    pred_saliency, l = self.setup(mode='Test')\n",
        "    saver = tf.train.Saver()\n",
        "    \n",
        "    with tf.Session() as sess:\n",
        "      #writer = tf.summary.FileWriter(logdir=\"./\", graph=sess.graph)\n",
        "      saver.restore(sess, 'model/latest1')\n",
        "      saliency = sess.run(pred_saliency, feed_dict={self.input_images_placeholder: test_imgs})\n",
        "      for i in range(len(test_imgs)):\n",
        "        print('saving images')\n",
        "        saliency_img = sess.run(tf.image.convert_image_dtype(saliency[i], tf.uint8))\n",
        "        imageio.imwrite(str(i)+'.jpg', saliency_img)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhmQ0g-1-GKV",
        "colab_type": "code",
        "outputId": "371c8bb7-615d-48e0-9f24-fdadeea9f99d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2315
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "train_imgs, train_fixations = load_train_data()\n",
        "\n",
        "my_model = saliencyModel(model_weights='/tmp/Model/VGG16/vgg16-conv-weights.npz', learning_rate=1e-1, num_epochs=1001, batch_size=32)\n",
        "\n",
        "my_model.train(train_imgs, train_fixations)\n",
        "#my_model.train(train_imgs, train_fixations)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IN_TRAINING_MODE is False\n",
            "IN_TRAINING_MODE is True\n",
            "epoch 0 done: TRAINING batch loss 0.04220879450440407\n",
            "epoch 0 VALIDATION batch loss 0.04745849221944809\n",
            "epoch 5 done: TRAINING batch loss 0.040625590831041336\n",
            "epoch 10 done: TRAINING batch loss 0.037076469510793686\n",
            "epoch 15 done: TRAINING batch loss 0.034870803356170654\n",
            "epoch 20 done: TRAINING batch loss 0.032245032489299774\n",
            "epoch 25 done: TRAINING batch loss 0.033933497965335846\n",
            "epoch 30 done: TRAINING batch loss 0.03210441395640373\n",
            "epoch 35 done: TRAINING batch loss 0.030861828476190567\n",
            "epoch 40 done: TRAINING batch loss 0.03681804984807968\n",
            "epoch 45 done: TRAINING batch loss 0.03717378154397011\n",
            "epoch 50 done: TRAINING batch loss 0.03486945107579231\n",
            "epoch 55 done: TRAINING batch loss 0.030342405661940575\n",
            "epoch 60 done: TRAINING batch loss 0.03193863108754158\n",
            "epoch 65 done: TRAINING batch loss 0.031751204282045364\n",
            "epoch 70 done: TRAINING batch loss 0.027446487918496132\n",
            "epoch 75 done: TRAINING batch loss 0.028628939762711525\n",
            "epoch 80 done: TRAINING batch loss 0.02862461470067501\n",
            "epoch 85 done: TRAINING batch loss 0.027680529281497\n",
            "epoch 90 done: TRAINING batch loss 0.029795000329613686\n",
            "epoch 95 done: TRAINING batch loss 0.025956418365240097\n",
            "epoch 100 done: TRAINING batch loss 0.028150586411356926\n",
            "epoch 100 VALIDATION batch loss 0.035091083496809006\n",
            "epoch 105 done: TRAINING batch loss 0.033019501715898514\n",
            "epoch 110 done: TRAINING batch loss 0.028426632285118103\n",
            "epoch 115 done: TRAINING batch loss 0.02910085767507553\n",
            "epoch 120 done: TRAINING batch loss 0.031059108674526215\n",
            "epoch 125 done: TRAINING batch loss 0.025639839470386505\n",
            "epoch 130 done: TRAINING batch loss 0.027034536004066467\n",
            "epoch 135 done: TRAINING batch loss 0.02713298611342907\n",
            "epoch 140 done: TRAINING batch loss 0.025827588513493538\n",
            "epoch 145 done: TRAINING batch loss 0.022023145109415054\n",
            "epoch 150 done: TRAINING batch loss 0.030637947842478752\n",
            "epoch 155 done: TRAINING batch loss 0.02847740240395069\n",
            "epoch 160 done: TRAINING batch loss 0.02650309167802334\n",
            "epoch 165 done: TRAINING batch loss 0.025067957118153572\n",
            "epoch 170 done: TRAINING batch loss 0.02418268844485283\n",
            "epoch 175 done: TRAINING batch loss 0.025042975321412086\n",
            "epoch 180 done: TRAINING batch loss 0.025231599807739258\n",
            "epoch 185 done: TRAINING batch loss 0.02736111544072628\n",
            "epoch 190 done: TRAINING batch loss 0.023608535528182983\n",
            "epoch 195 done: TRAINING batch loss 0.022681403905153275\n",
            "epoch 200 done: TRAINING batch loss 0.022075258195400238\n",
            "epoch 200 VALIDATION batch loss 0.02427803725004196\n",
            "epoch 205 done: TRAINING batch loss 0.026428837329149246\n",
            "epoch 210 done: TRAINING batch loss 0.022873593494296074\n",
            "epoch 215 done: TRAINING batch loss 0.021248968318104744\n",
            "epoch 220 done: TRAINING batch loss 0.02194894850254059\n",
            "epoch 225 done: TRAINING batch loss 0.024036604911088943\n",
            "epoch 230 done: TRAINING batch loss 0.02227133698761463\n",
            "epoch 235 done: TRAINING batch loss 0.024301066994667053\n",
            "epoch 240 done: TRAINING batch loss 0.022817132994532585\n",
            "epoch 245 done: TRAINING batch loss 0.02264503948390484\n",
            "epoch 250 done: TRAINING batch loss 0.022793719545006752\n",
            "epoch 255 done: TRAINING batch loss 0.024439256638288498\n",
            "epoch 260 done: TRAINING batch loss 0.02143680863082409\n",
            "epoch 265 done: TRAINING batch loss 0.02258184365928173\n",
            "epoch 270 done: TRAINING batch loss 0.020205099135637283\n",
            "epoch 275 done: TRAINING batch loss 0.021365275606513023\n",
            "epoch 280 done: TRAINING batch loss 0.02081284485757351\n",
            "epoch 285 done: TRAINING batch loss 0.023094674572348595\n",
            "epoch 290 done: TRAINING batch loss 0.022840524092316628\n",
            "epoch 295 done: TRAINING batch loss 0.023122059181332588\n",
            "epoch 300 done: TRAINING batch loss 0.022186439484357834\n",
            "epoch 300 VALIDATION batch loss 0.022706523537635803\n",
            "epoch 305 done: TRAINING batch loss 0.022444788366556168\n",
            "epoch 310 done: TRAINING batch loss 0.02221320942044258\n",
            "epoch 315 done: TRAINING batch loss 0.022531962022185326\n",
            "epoch 320 done: TRAINING batch loss 0.022819319739937782\n",
            "epoch 325 done: TRAINING batch loss 0.02065443806350231\n",
            "epoch 330 done: TRAINING batch loss 0.021189464256167412\n",
            "epoch 335 done: TRAINING batch loss 0.020513640716671944\n",
            "epoch 340 done: TRAINING batch loss 0.02158600464463234\n",
            "epoch 345 done: TRAINING batch loss 0.021672381088137627\n",
            "epoch 350 done: TRAINING batch loss 0.02117445506155491\n",
            "epoch 355 done: TRAINING batch loss 0.020031575113534927\n",
            "epoch 360 done: TRAINING batch loss 0.01993907056748867\n",
            "epoch 365 done: TRAINING batch loss 0.019262144342064857\n",
            "epoch 370 done: TRAINING batch loss 0.02359452098608017\n",
            "epoch 375 done: TRAINING batch loss 0.022083621472120285\n",
            "epoch 380 done: TRAINING batch loss 0.021765822544693947\n",
            "epoch 385 done: TRAINING batch loss 0.02464005909860134\n",
            "epoch 390 done: TRAINING batch loss 0.01972462609410286\n",
            "epoch 395 done: TRAINING batch loss 0.02070077508687973\n",
            "epoch 400 done: TRAINING batch loss 0.020849475637078285\n",
            "epoch 400 VALIDATION batch loss 0.02250153385102749\n",
            "epoch 405 done: TRAINING batch loss 0.022153623402118683\n",
            "epoch 410 done: TRAINING batch loss 0.02091468684375286\n",
            "epoch 415 done: TRAINING batch loss 0.019264034926891327\n",
            "epoch 420 done: TRAINING batch loss 0.021783463656902313\n",
            "epoch 425 done: TRAINING batch loss 0.021004632115364075\n",
            "epoch 430 done: TRAINING batch loss 0.02119806967675686\n",
            "epoch 435 done: TRAINING batch loss 0.01894935593008995\n",
            "epoch 440 done: TRAINING batch loss 0.018751313909888268\n",
            "epoch 445 done: TRAINING batch loss 0.022356344386935234\n",
            "epoch 450 done: TRAINING batch loss 0.019464829936623573\n",
            "epoch 455 done: TRAINING batch loss 0.021687259897589684\n",
            "epoch 460 done: TRAINING batch loss 0.01985331065952778\n",
            "epoch 465 done: TRAINING batch loss 0.02136332355439663\n",
            "epoch 470 done: TRAINING batch loss 0.020096031948924065\n",
            "epoch 475 done: TRAINING batch loss 0.02137773111462593\n",
            "epoch 480 done: TRAINING batch loss 0.02294696308672428\n",
            "epoch 485 done: TRAINING batch loss 0.01915360428392887\n",
            "epoch 490 done: TRAINING batch loss 0.019738050177693367\n",
            "epoch 495 done: TRAINING batch loss 0.0193338580429554\n",
            "epoch 500 done: TRAINING batch loss 0.020902954041957855\n",
            "epoch 500 VALIDATION batch loss 0.021326575428247452\n",
            "epoch 505 done: TRAINING batch loss 0.019183726981282234\n",
            "epoch 510 done: TRAINING batch loss 0.02071763388812542\n",
            "epoch 515 done: TRAINING batch loss 0.021948084235191345\n",
            "epoch 520 done: TRAINING batch loss 0.018577713519334793\n",
            "epoch 525 done: TRAINING batch loss 0.021466942504048347\n",
            "epoch 530 done: TRAINING batch loss 0.02291218191385269\n",
            "epoch 535 done: TRAINING batch loss 0.019897622987627983\n",
            "epoch 540 done: TRAINING batch loss 0.018185768276453018\n",
            "epoch 545 done: TRAINING batch loss 0.020686376839876175\n",
            "epoch 550 done: TRAINING batch loss 0.019421473145484924\n",
            "epoch 555 done: TRAINING batch loss 0.019963666796684265\n",
            "epoch 560 done: TRAINING batch loss 0.019723648205399513\n",
            "epoch 565 done: TRAINING batch loss 0.021684568375349045\n",
            "epoch 570 done: TRAINING batch loss 0.020750436931848526\n",
            "epoch 575 done: TRAINING batch loss 0.01918051764369011\n",
            "epoch 580 done: TRAINING batch loss 0.020808275789022446\n",
            "epoch 585 done: TRAINING batch loss 0.01991422474384308\n",
            "epoch 590 done: TRAINING batch loss 0.018451647832989693\n",
            "epoch 595 done: TRAINING batch loss 0.021978246048092842\n",
            "epoch 600 done: TRAINING batch loss 0.01853535696864128\n",
            "epoch 600 VALIDATION batch loss 0.019373690709471703\n",
            "epoch 605 done: TRAINING batch loss 0.017838243395090103\n",
            "epoch 610 done: TRAINING batch loss 0.020789859816432\n",
            "epoch 615 done: TRAINING batch loss 0.018153736367821693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1M8GSkh-GVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "train_imgs, train_fixations = load_train_data()\n",
        "\n",
        "my_model = saliencyModel(model_weights='/tmp/Model/VGG16/vgg16-conv-weights.npz', learning_rate=1e-1, num_batches=1001, batch_size=16)\n",
        "\n",
        "my_model.test(train_imgs[0:16])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixmakTnm-GjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}